{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FACE MASK DETECTOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block of Code Used for Scraping Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for scraping the pictures for our datasets ( for training our Deep Learning Model ) from BingImageCrawler\n",
    "'''\n",
    "from icrawler.builtin import BingImageCrawler\n",
    "for keyword in ['person face smiling']:\n",
    "    crawler =  BingImageCrawler(\n",
    "        parser_threads=2,\n",
    "        downloader_threads=4,\n",
    "        storage={'root_dir': 'C:/Users/Tarun/Desktop/comp/projects/face_mask_detector/dataset/training_set/no_mask_1'} #storage={root_dir':'C:/Users/Tarun/Desktop/comp/image1/{}'.format(keyword)}\n",
    "    )\n",
    "    crawler.crawl(keyword=keyword, max_num=1, min_size=(200, 200))  '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential #initialise the neural network as its a sequence of layers\n",
    "from keras.layers import Conv2D #import convolutional layers\n",
    "from keras.layers import MaxPooling2D #import pooling layers which have max function\n",
    "from keras.layers import Flatten #import flatten layer\n",
    "from keras.layers import Dense #add the layers to the ann\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu')) #32 is number of feature detectors having dimensions (3,3),input_shape is format into which images will be converted .. 3 channels (rgb) of 64 * 64 coloured pixels, relu function for non-colinearity\n",
    "\n",
    "# Step 2 - Pooling .. reducing size of the feature maps\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2))) #2,2 is used so that we dont loose information and also be precise in where features are detected\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu')) #no. of nodes = 128 ( in power of 2 ), number around 100 is good \n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid')) # binary output\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy']) # binary cross entropy algorithm used to distinguish between the 2 classes\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator #preprocesses images to prevent overfitting and enrichs our training set without increasing the number of images\n",
    "\n",
    "#used for getting different variations of our data (in this case pictures) as we only have a limited dataset\n",
    "\n",
    "#ImageDataGenerator for training data\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "#ImageDataGenerator for test data\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 1000,\n",
    "                         epochs = 1, #reduce number of epochs because c;u times out, originally 25\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000)\n",
    "\n",
    "# Saving model to disk\n",
    "classifier.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if our model works on a single picture\n",
    "from keras.preprocessing import image\n",
    "from keras import models\n",
    "import numpy as np\n",
    "\n",
    "#loading the trained model\n",
    "model = models.load_model('model.h5')\n",
    "#testing on a single picture\n",
    "test_image=image.load_img('dataset/single_pred/0.jpg',target_size = (64, 64))\n",
    "#converts it into 3d array\n",
    "test_image=image.img_to_array(test_image) #converts it into 3d array\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "\n",
    "#finding the prediction by inputting the array into the model\n",
    "prediction=model.predict([test_image])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Model Live and Testing Through a Webcam Feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "from keras import models\n",
    "\n",
    "#loading the model\n",
    "model = models.load_model('model.h5')\n",
    "#getting the object from the webcam ( default webcam input is at 0)\n",
    "cap = cv2.VideoCapture(0) \n",
    "\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image\n",
    "\n",
    "#using haarcascade_frontalface to detect the face\n",
    "face_cascade = cv2.CascadeClassifier('C:/Users/Tarun/Desktop/comp/projects/face_mask_detector/haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "#main function to detect the face and if a mask is present\n",
    "def detect_face(img):\n",
    "    \n",
    "    #getting a copy of the frame\n",
    "    face_img = img.copy()\n",
    "    #detecting the face from the frame\n",
    "    face_rects = face_cascade.detectMultiScale(face_img)\n",
    "    \n",
    "    for (face_x,face_y,w,h) in face_rects:\n",
    "        #getting the region of interest of the face\n",
    "        roi = frame[face_y:face_y+h, face_x:face_x+w]\n",
    "        #resizing to suit our model\n",
    "        roi = cv2.resize(roi, (64,64))\n",
    "        #saving as image so as to make changing of sizes and changing to arrays easier for us\n",
    "        cv2.imwrite('frame.jpg', roi)\n",
    "        roi=image.load_img('frame.jpg',target_size = (64, 64))\n",
    "        #converts it into 3d array\n",
    "        img_array=image.img_to_array(roi) #converts it into 3d array\n",
    "        img_array=np.expand_dims(img_array,axis=0)\n",
    "        \n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "        #predicting by passing array into the model\n",
    "        predict=model.predict([img_array])\n",
    "        import winsound     \n",
    "        import time\n",
    "        #getting the predicition value from the array\n",
    "        #if human is not wearing a mask , an alarm starts beeping\n",
    "        if(predict==[[1.]]):\n",
    "            prediction=\"No Mask !!\"\n",
    "            winsound.Beep((1500), 50)\n",
    "        else:\n",
    "            prediction=\"Mask found !\"\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.rectangle(img, (face_x,face_y), (face_x+w,face_y+h), (255,255,255), 2)\n",
    "        cv2.putText(img,prediction,(0,130), font, 1, (200,255,155), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return img\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "while True: \n",
    "    #getting frames from webcam\n",
    "    ret, frame = cap.read(0) \n",
    "    #passing frames to the emotions detection function\n",
    "    frame = detect_face(frame)\n",
    "    #final outputting of the frame \n",
    "    cv2.imshow('Mask detection', frame) \n",
    "    c = cv2.waitKey(1) \n",
    "    if c == 27: \n",
    "        break \n",
    "        \n",
    "cap.release() \n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
